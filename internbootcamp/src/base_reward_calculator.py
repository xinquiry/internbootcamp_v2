import random
from abc import abstractmethod
import json
from json import JSONDecodeError

class BaseRewardCalculator:

    @abstractmethod
    def extract_output(output_str: str):
        """
        output_str: Final reponse
        
        Returns:
            extracted information for reward calculation
        """
        pass
    
    @abstractmethod
    def _verify_correction(self, extract_solution: dict, identity: dict, **kwargs) -> float:
        """
        Verify the extracted solution against the ground truth and compute a correctness score.
        """
        pass
    
    @classmethod
    def verify_score(cls, model_output, identity: dict, format_score=0, short_penalty=False, short_threshold=256, think_threshold=0, ans_threshold=256, format_penalty=False, **kwargs) -> float:
        """
        Verify the model output against the ground truth and compute a correctness score.
        
        The verification involves:
        - Optional format validation (e.g., presence and structure of <think>...</think> tags).
        - Extraction of the solution from the output.
        - Semantic or structural comparison with the ground truth via _verify_correction.
        - Optional penalties for outputs that are too short in total length, reasoning section, or answer section.

        Args:
            model_output (str): The full output string generated by the model.
            identity (dict): Ground truth or reference information used for verification. 
                             Typically contains expected answer, solution, or other validation rules.
            format_score (float): Base score awarded for correct output format (before content evaluation).
                                  If format is invalid, this score may not be applied.
            short_penalty (bool): Whether to apply a penalty if the output is too short.
            short_threshold (int): Minimum total length of the model output to avoid penalty.
            think_threshold (int): Minimum length required for the <think> reasoning section.
            ans_threshold (int): Minimum length required for the final answer (after </think>).
            format_penalty (bool): If True, enforces strict formatting rules:
                                   - Must start with <think> and contain exactly one <think> and one </think>.
                                   - Invalid format results in score 0.

        Returns:
            float: A score between 0 and 1 (or higher if format_score > 1), representing the correctness
                   of the model output. Returns 0 if format is invalid (when format_penalty is enabled) 
                   or if the output is too short (when short_penalty is enabled). 
                   The score may be reduced proportionally based on how much the length thresholds are violated.

        Notes:
            - The function first checks format validity if `format_penalty` is enabled.
            - Then extracts the solution using `cls.extract_output`.
            - Compares the extracted solution with `identity` via `cls._verify_correction`, which can return:
                - True: full correctness (score = 1.0)
                - False: incorrect (score remains at format_score or 0)
                - float/int: a custom score (e.g., partial credit)
            - Length penalties are applied multiplicatively if `short_penalty` is True and any length condition is violated.
        """
        score = 0. 
        
        # identity类型限制
        if not isinstance(identity, dict):
            try:
                identity = json.loads(identity)
            except JSONDecodeError as e:
                pass
            except TypeError as e:
                pass
            except Exception as e:
                print(f"[DEBUG BaseRewardCalculator] Error in verify_score: identity is not a dict")
                return 0.0
        if format_penalty and ("<think>" not in model_output or "</think>" not in model_output):
            return score
        if format_penalty and (model_output.count("<think>") > 1 or model_output.count("</think>") > 1 or model_output.count("<think>") != model_output.count("</think>") or not model_output.startswith("<think>") or model_output.endswith("</think>")):
            # should not end with </think>
            return score
        try:
            extract_solution = cls.extract_output(model_output)
            if extract_solution is None:
                return score
            else:
                score = format_score # 必须在这里就给format_score 赋值！否则后面verify_correction如果报错，format_score就没有赋值
            judge =  cls._verify_correction(extract_solution, identity, **kwargs)
            if type(judge) == bool and judge:
                score = 1.
            else:
                # 更宽松的类型检查，接受数值类型
                if isinstance(judge, (bool, int, float)):
                    score = float(judge)
                else:
                    print(f"[DEBUG BaseRewardCalculator] 警告：_verify_correction返回了意外类型 {type(judge)}: {judge}")
                    score = 0.0
                # assert type(judge) == float or type(judge) == int
                # score = float(judge)   
        except Exception as e:
            print(f"[DEBUG BaseRewardCalculator] Error in verify_score: {str(e)}")
            import traceback
            print(f"[DEBUG BaseRewardCalculator] Exception traceback:\n{traceback.format_exc()}")
            return 0.0  # 返回数值分数而不是字符串
            # print("Error in verify_score:", e)
            # return str(e)
            # pass
        ans_output = model_output.rsplit("</think>", 1)[1] if "</think>" in model_output else ""
        think_length = len(model_output) - len(ans_output)
        score = max(0, score)  # Ensure score is non-negative
        if (short_penalty and len(model_output) < short_threshold) or (short_penalty and len(ans_output) < ans_threshold) or (short_penalty and think_length < think_threshold):
            # if the output is too short, consider it incorrect
            return min(score * len(model_output) / short_threshold, score * len(ans_output) / ans_threshold, score * think_length / think_threshold)
        
        # This for training Debug
        # if random.randint(1,1024) == 1:
        #     print("=============DEBUG=============")
        #     print("model_output:\n", model_output)
        #     print("identity:\n", identity)
        #     print("extract_solution:\n", extract_solution)
        #     print("score:", score)
        #     print("===============================")
        
        return score