#!/usr/bin/env python3
"""
é€šç”¨å‘½ä»¤è¡Œè¯„æµ‹è„šæœ¬

è¿™ä¸ªè„šæœ¬æä¾›äº†ä¸€ä¸ªé€šç”¨çš„å‘½ä»¤è¡Œæ¥å£æ¥è¿è¡Œå„ç§è¯„æµ‹ä»»åŠ¡ã€‚
æ”¯æŒåŠ¨æ€åŠ è½½è¯„æµ‹å™¨ã€é…ç½®å·¥å…·å’Œæ•°æ®é›†ï¼Œæä¾›çµæ´»çš„è¯„æµ‹æ¡†æ¶ã€‚
"""

import argparse
import asyncio
import importlib
import os
import ast
import sys
import json
import traceback
from typing import Dict, Any, Optional, List


from internbootcamp.src.base_evaluator import BaseEvaluator
from internbootcamp.utils.load_class_from_str import load_class_from_string

def create_evaluator(
    evaluator_class: str = None,
    api_url: str = None,
    api_key: str = None,
    api_model: str = "gpt-3.5-turbo",
    reward_calculator = None,
    max_assistant_turns: int = 10,
    max_user_turns: int = 5,
    api_extra_headers: Optional[Dict] = None,
    api_extra_params: Optional[Dict] = None,
    verify_correction_kwargs: Optional[Dict] = None,
    **kwargs
):
    """
    åˆ›å»ºè¯„æµ‹å™¨å®ä¾‹
    
    Args:
        evaluator_class: è¯„æµ‹å™¨ç±»è·¯å¾„
        api_url: API URL
        api_key: API å¯†é’¥
        api_model: æ¨¡å‹åç§°
        reward_calculator: å¥–åŠ±è®¡ç®—å™¨å®ä¾‹
        max_assistant_turns: assistantå“åº”çš„æœ€å¤§è½®æ¬¡
        max_user_turns: userè¾“å…¥çš„æœ€å¤§è½®æ¬¡
        api_extra_headers: é¢å¤–çš„APIå¤´éƒ¨
        api_extra_params: é¢å¤–çš„æ¨¡å‹å‚æ•°ï¼ˆå¦‚temperatureã€max_tokensç­‰ï¼‰
        verify_correction_kwargs: ä¼ é€’ç»™å¥–åŠ±è®¡ç®—å™¨verify_correctionæ–¹æ³•çš„é¢å¤–å‚æ•°
        **kwargs: ä¼ é€’ç»™è¯„æµ‹å™¨çš„é¢å¤–å‚æ•°
        
    Returns:
        è¯„æµ‹å™¨å®ä¾‹
    """
    if evaluator_class:
        evaluator_cls = load_class_from_string(evaluator_class)
    else:
        evaluator_cls = BaseEvaluator
    
    return evaluator_cls(
        api_url=api_url,
        api_key=api_key,
        api_model=api_model,
        reward_calculator=reward_calculator,
        max_assistant_turns=max_assistant_turns,
        max_user_turns=max_user_turns,
        api_extra_headers=api_extra_headers,
        api_extra_params=api_extra_params,
        verify_correction_kwargs=verify_correction_kwargs,
        **kwargs
    )


def parse_extra_headers(headers_str: str) -> Dict[str, str]:
    """
    è§£æé¢å¤–çš„HTTPå¤´éƒ¨å‚æ•°
    
    Args:
        headers_str: æ ¼å¼å¦‚ "key1:value1,key2:value2" çš„å­—ç¬¦ä¸²
        
    Returns:
        è§£æåçš„å¤´éƒ¨å­—å…¸
    """
    headers = {}
    if headers_str:
        for header in headers_str.split(','):
            if ':' in header:
                key, value = header.split(':', 1)
                headers[key.strip()] = value.strip()
    return headers


def parse_extra_params(params_str: str) -> Dict[str, any]:
    """
    è§£æé¢å¤–çš„æ¨¡å‹å‚æ•°
    
    Args:
        params_str: æ”¯æŒä»¥ä¸‹ä¸¤ç§å½¢å¼ä¹‹ä¸€ï¼š
            1) JSON å­—ç¬¦ä¸²ï¼ˆæ¨èï¼‰ï¼šä¾‹å¦‚ '{"temperature":0.7,"max_tokens":2048}' æˆ–åµŒå¥—ç»“æ„
            2) ä»¥ '@' å¼€å¤´çš„æ–‡ä»¶è·¯å¾„ï¼šä¾‹å¦‚ '@/path/to/params.json'ï¼ˆæ–‡ä»¶å†…å®¹ä¸º JSONï¼‰
        åŒæ—¶ä¿ç•™å¯¹æ—§æ ¼å¼ "k:v,k2:v2" çš„å…¼å®¹ä½œä¸ºå›é€€è§£æã€‚
        
    Returns:
        è§£æåçš„å‚æ•°å­—å…¸
    """
    if not params_str:
        return {}

    text = params_str.strip()

    # æƒ…å†µ 1ï¼š@æ–‡ä»¶ è·¯å¾„ï¼ˆæ–‡ä»¶å†…å®¹ä¸º JSONï¼‰
    if text.startswith('@'):
        file_path = text[1:]
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"å‚æ•°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        try:
            loaded = json.loads(content)
        except json.JSONDecodeError as e:
            raise ValueError(f"å‚æ•°æ–‡ä»¶ JSON è§£æå¤±è´¥: {e}")
        if not isinstance(loaded, dict):
            raise ValueError("å‚æ•°æ–‡ä»¶çš„ JSON æ ¹ç±»å‹å¿…é¡»ä¸ºå¯¹è±¡(dict)")
        return loaded

    # æƒ…å†µ 2ï¼šç›´æ¥ä½œä¸º JSON å­—ç¬¦ä¸²
    try:
        loaded = json.loads(text)
        if isinstance(loaded, dict):
            return loaded
        else:
            raise ValueError("JSON æ ¹ç±»å‹å¿…é¡»ä¸ºå¯¹è±¡(dict)")
    except json.JSONDecodeError:
        # ç»§ç»­å°è¯•å›é€€åˆ°æ—§æ ¼å¼è§£æ
        try:
            loaded = ast.literal_eval(text)
            if isinstance(loaded, dict):
                return loaded
        except Exception:
            print(f"Depreciated Warning: {text} é¢å¤–å‚æ•°æœªèƒ½è§£æä¸º JSON æ ¼å¼ï¼Œå°†ä½¿ç”¨æ—§æ ¼å¼è§£æã€‚è¯·ä¼˜å…ˆè€ƒè™‘ä½¿ç”¨ JSON æ ¼å¼ä¼ é€’å‚æ•°ã€‚")

    # å›é€€ï¼šæ—§æ ¼å¼ "k:v,k2:v2"ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    params: Dict[str, Any] = {}
    for param in text.split(','):
        if ':' not in param:
            continue
        key, value = param.split(':', 1)
        key = key.strip()
        value = value.strip()

        # è‡ªåŠ¨è½¬æ¢ç±»å‹ï¼ˆint/float/boolï¼‰ï¼Œå¦åˆ™å­—ç¬¦ä¸²
        try:
            if value.isdigit() or (value.startswith('-') and value[1:].isdigit()):
                params[key] = int(value)
            elif '.' in value:
                # å°è¯• floatï¼›è‹¥å¤±è´¥åˆ™ä¿ç•™å­—ç¬¦ä¸²
                params[key] = float(value)
            elif value.lower() in ('true', 'false'):
                params[key] = value.lower() == 'true'
            else:
                params[key] = value
        except ValueError:
            params[key] = value

    return params


def main():
    parser = argparse.ArgumentParser(
        description="é€šç”¨å‘½ä»¤è¡Œè¯„æµ‹è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹: Bootcampv2/example_bootcamp/examples/run_example_evaluation.sh
"""
    )
    
    parser.add_argument('--dataset-path', type=str, help='æ•°æ®é›†æ–‡ä»¶è·¯å¾„ (.json, .jsonl, .parquet)')
    parser.add_argument('--output-dir', type=str, help='è¯„æµ‹ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--api-key', type=str, help='API å¯†é’¥')
    parser.add_argument('--api-url', type=str, default=None, help='API URL (å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤çš„OpenAI API)')
    parser.add_argument('--api-model', type=str, default='gpt-3.5-turbo', help='æ¨¡å‹åç§° (é»˜è®¤: gpt-3.5-turbo)')
    parser.add_argument('--api-extra-headers', type=str, default=None, help='é¢å¤–çš„APIå¤´éƒ¨ï¼Œæ ¼å¼: "key1:value1,key2:value2"')
    parser.add_argument('--api-extra-params', type=str, default=None, help='é¢å¤–çš„æ¨¡å‹å‚æ•°ï¼›æ”¯æŒ JSON å­—ç¬¦ä¸²æˆ– @æ–‡ä»¶ï¼ˆJSONï¼‰ã€‚ç¤ºä¾‹ï¼š\n  1) JSON å­—ç¬¦ä¸²ï¼š\n     --api-extra-params \'{"temperature":0.7, "max_completion_tokens":65536, "extra_body": {"enable_thinking": true}}\'\n  2) ä»æ–‡ä»¶è¯»å–ï¼ˆä»¥ @ å¼€å¤´ï¼‰ï¼š\n     --api-extra-params @/path/to/params.json\n  3) å›é€€å…¼å®¹æ—§æ ¼å¼ï¼š"temperature:0.7,max_tokens:2048,top_p:0.9"')
    parser.add_argument('--verify-correction-kwargs', type=str, default=None, help='é¢å¤–çš„å¥–åŠ±è®¡ç®—å‡½æ•°å‚æ•°ï¼›æ”¯æŒæ ¼å¼åŒapi-extra-params(è¯¥å‚æ•°è§£åŒ…ä¼ é€’ç»™reward calculatorçš„verify correctionæ–¹æ³•)')
    parser.add_argument('--evaluator-class', type=str, default=None, help='è¯„æµ‹å™¨ç±»è·¯å¾„ (å¦‚: internbootcamp.bootcamps.example_bootcamp.example_evaluator.ExampleEvaluator)')
    parser.add_argument('--reward-calculator-class', type=str, default=None, help='å¥–åŠ±è®¡ç®—å™¨ç±»è·¯å¾„ (å¦‚: internbootcamp.bootcamps.example_bootcamp.example_reward_calculator.ExampleRewardCalculator)')
    parser.add_argument('--tool-config', type=str, default=None, help='å·¥å…·é…ç½®YAMLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--interaction-config', type=str, default=None, help='äº¤äº’é…ç½®YAMLæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-tool-turns-per-interaction', type=int, default=None, help='æ¯æ¬¡äº¤äº’çš„æœ€å¤§å·¥å…·è°ƒç”¨è½®æ¬¡ (å·²å¼ƒç”¨)')
    parser.add_argument('--max-interaction-turns', type=int, default=None, help='æœ€å¤§äº¤äº’è½®æ¬¡ (å·²å¼ƒç”¨)')
    parser.add_argument('--max-assistant-turns', type=int, default=None, help='assistantå“åº”çš„æœ€å¤§è½®æ¬¡ (é»˜è®¤: Noneï¼Œæ— é™åˆ¶)')
    parser.add_argument('--max-user-turns', type=int, default=None, help='userè¾“å…¥çš„æœ€å¤§è½®æ¬¡(åŒ…æ‹¬tool response, interaction response) (é»˜è®¤: Noneï¼Œæ— é™åˆ¶)')
    parser.add_argument('--max-concurrent', type=int, default=1, help='æœ€å¤§å¹¶å‘æ•° (é»˜è®¤: 1)')
    parser.add_argument('--verbose', action='store_true', help='è¾“å‡ºè¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--dry-run', action='store_true', help='åªéªŒè¯é…ç½®ï¼Œä¸å®é™…è¿è¡Œè¯„æµ‹')
    parser.add_argument('--tokenizer-path', type=str, default=None, nargs='?', const=None, help='tokenizerè·¯å¾„(å¯é€‰, apply templateæ—¶ä½¿ç”¨)')
    parser.add_argument('--bootcamp-registry', type=str, default=None, help='bootcampæ³¨å†Œè¡¨è·¯å¾„(å¯é€‰, ç”¨äºæ‰¹é‡è¯„æµ‹)')
    parser.add_argument('--resume-from-result-path', type=str, default=None, help='æ–­ç‚¹é‡è¯•æ¨¡å¼ï¼šæŒ‡å®šè¦æ¢å¤çš„ç»“æœæ–‡ä»¶è·¯å¾„(.jsonl)')
    parser.add_argument('--max-iterations', type=int, default=None, help='å•è½®æ•°æ®æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆç”¨äºå•è½®è¯„æµ‹ï¼‰')
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.dataset_path):
        print(f"âŒ é”™è¯¯: æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {args.dataset_path}")
        sys.exit(1)
    
    # éªŒè¯æ–­ç‚¹é‡è¯•æ–‡ä»¶
    if args.resume_from_result_path and not os.path.exists(args.resume_from_result_path):
        print(f"âŒ é”™è¯¯: æ–­ç‚¹é‡è¯•æ–‡ä»¶ä¸å­˜åœ¨: {args.resume_from_result_path}")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # å¤„ç†å‚æ•°å…¼å®¹æ€§
    if args.max_tool_turns_per_interaction:
        print("âš ï¸  è­¦å‘Š: --max-tool-turns-per-interactionå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨--max-assistant-turnsä»£æ›¿")
    if args.max_interaction_turns:
        print("âš ï¸  è­¦å‘Š: --max-interaction-turnså·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨--max-assistant-turnsä»£æ›¿")
    
    if args.verbose:
        print("ğŸ”§ é…ç½®ä¿¡æ¯:")
        print(f"  æ•°æ®é›†è·¯å¾„: {args.dataset_path}")
        print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"  APIæ¨¡å‹: {args.api_model}")
        print(f"  å·¥å…·é…ç½®è·¯å¾„ (tool config): {args.tool_config if args.tool_config else 'æ— '}")
        print(f"  äº¤äº’é…ç½®è·¯å¾„ (interaction config): {args.interaction_config if args.interaction_config else 'æ— '}")
        print(f"  æœ€å¤§assistantè½®æ¬¡: {args.max_assistant_turns}")
        print(f"  æœ€å¤§userè½®æ¬¡: {args.max_user_turns}")
        print(f"  æœ€å¤§å¹¶å‘: {args.max_concurrent}")
        print(f"  é¢å¤–APIå¤´éƒ¨: {args.api_extra_headers if args.api_extra_headers else 'æ— '}")
        print(f"  é¢å¤–æ¨¡å‹å‚æ•°: {args.api_extra_params if args.api_extra_params else 'æ— '}")
        print(f"  éªŒè¯ä¿®æ­£å‚æ•°: {args.verify_correction_kwargs if args.verify_correction_kwargs else 'æ— '}")
        print(f"  æ–­ç‚¹é‡è¯•: {'å¯ç”¨ (' + args.resume_from_result_path + ')' if args.resume_from_result_path else 'ç¦ç”¨'}")
        print(f"  æœ€å¤§è¿­ä»£æ¬¡æ•°: {args.max_iterations if args.max_iterations else 'æ— '}")
    try:
        # è§£æé¢å¤–å¤´éƒ¨å’Œå‚æ•°
        extra_headers = parse_extra_headers(args.api_extra_headers) if args.api_extra_headers else None
        extra_params = parse_extra_params(args.api_extra_params) if args.api_extra_params else None
        verify_correction_kwargs = parse_extra_params(args.verify_correction_kwargs) if args.verify_correction_kwargs else None
        
        # åˆ›å»ºå¥–åŠ±ç®¡ç†å™¨
        if args.verbose:
            print("ğŸ“Š æ­£åœ¨åˆ›å»ºå¥–åŠ±è®¡ç®—å™¨...")
        if args.reward_calculator_class:
            reward_calculator = load_class_from_string(args.reward_calculator_class)
        else:
            reward_calculator = None
        
        # åˆ›å»ºè¯„æµ‹å™¨
        if args.verbose:
            print("ğŸ¤– æ­£åœ¨åˆ›å»ºè¯„æµ‹å™¨...")
        evaluator = create_evaluator(
            evaluator_class=args.evaluator_class,
            api_url=args.api_url,
            api_key=args.api_key,
            api_model=args.api_model,
            reward_calculator=reward_calculator,
            max_assistant_turns=args.max_assistant_turns,
            max_user_turns=args.max_user_turns,
            api_extra_headers=extra_headers,
            api_extra_params=extra_params,
            verify_correction_kwargs=verify_correction_kwargs,
            tokenizer_path=args.tokenizer_path,
            max_iterations=args.max_iterations
        )
        
        if args.dry_run:
            print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼(å¹²è¿è¡Œæ¨¡å¼)")
            return
        
        # è¿è¡Œè¯„æµ‹ - ç›´æ¥ä½¿ç”¨base_evaluatorçš„run_evaluationæ–¹æ³•
        asyncio.run(evaluator.run_evaluation(
            dataset_path=args.dataset_path,
            output_dir=args.output_dir,
            yaml_tool_path=args.tool_config,
            yaml_interaction_path=args.interaction_config,
            max_concurrent=args.max_concurrent,
            bootcamp_registry=args.bootcamp_registry,
            resume_from_result_path=args.resume_from_result_path
        ))
        
    except Exception as e:
        print(f"âŒ è¯„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        if args.verbose:
            print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 