#!/usr/bin/env python3
"""
åˆ†å¸ƒå¼å·¥å…·æœåŠ¡å™¨å‘½ä»¤è¡Œç•Œé¢

æ”¯æŒMasterå’ŒWorkeråœ¨ä¸åŒæœºå™¨ä¸Šéƒ¨ç½²ï¼ŒWorkerå¯ä»¥åŠ¨æ€æ³¨å†Œåˆ°Masterã€‚

ä½¿ç”¨æ–¹æ³•:
1. å¯åŠ¨MasteræœåŠ¡å™¨ï¼š
   python cli.py --mode master --tools_yaml_path config.yaml --port 8000

2. åœ¨å…¶ä»–æœºå™¨ä¸Šå¯åŠ¨Workerï¼š
   python cli.py --mode worker --tools_yaml_path config.yaml --master_url http://master_ip:8000 --port 8001 --num_workers 3

3. å¯åŠ¨ç»Ÿä¸€æœåŠ¡å™¨ï¼ˆå•æœºæ¨¡å¼ï¼‰ï¼š
   python cli.py --mode unified --tools_yaml_path config.yaml --port 8000 --num_workers 5
"""

import argparse
import json
import jsonlines
import multiprocessing
import os
import re
import signal
import socket
import sys
import time
import uuid
import yaml
import random
from datetime import datetime
from pathlib import Path

import requests

from .master_server import DistributedMasterServer
from .worker_server import DistributedWorkerServer
from .utils import (
    load_tools_config, 
    get_external_ip, 
    find_available_port, 
    update_tools_config_with_urls
)


def redirect_output_to_log(log_file_path, process_name):
    """é‡å®šå‘stdoutå’Œstderråˆ°æ—¥å¿—æ–‡ä»¶"""
    if log_file_path:
        try:
            log_file = open(log_file_path, 'a', encoding='utf-8')
            # å†™å…¥è¿›ç¨‹å¯åŠ¨æ ‡è®°
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            log_file.write(f"[{timestamp}] === {process_name} è¿›ç¨‹å¯åŠ¨ ===\n")
            log_file.flush()
            
            # é‡å®šå‘stdoutå’Œstderr
            sys.stdout = log_file
            sys.stderr = log_file
        except Exception as e:
            print(f"è­¦å‘Šï¼šæ— æ³•é‡å®šå‘æ—¥å¿—åˆ° {log_file_path}: {e}")


def start_master_process(tools_config, host, port, log_file=None):
    """åœ¨å­è¿›ç¨‹ä¸­å¯åŠ¨MasteræœåŠ¡å™¨"""
    # é‡å®šå‘è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶
    redirect_output_to_log(log_file, f"Master-{host}:{port}")
    
    master = DistributedMasterServer(host, port, tools_config, log_file=log_file)
    master.run()


def start_worker_process(tools_config, host, port, worker_id, master_url, log_file=None):
    """åœ¨å­è¿›ç¨‹ä¸­å¯åŠ¨WorkeræœåŠ¡å™¨"""
    # è®¾ç½®æ— ç¼“å†²è¾“å‡º
    sys.stdout.reconfigure(line_buffering=True) if hasattr(sys.stdout, 'reconfigure') else None
    sys.stderr.reconfigure(line_buffering=True) if hasattr(sys.stderr, 'reconfigure') else None
    
    # é‡å®šå‘è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if log_file:
        redirect_output_to_log(log_file, f"Worker-{worker_id}")
    else:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥å¿—æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªä¸´æ—¶æ—¥å¿—æ–‡ä»¶
        temp_log_file = f"/tmp/worker_{worker_id}.log"
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(temp_log_file), exist_ok=True)
            # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
            with open(temp_log_file, 'w') as f:
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                f.write(f"[{timestamp}] Worker {worker_id} å­è¿›ç¨‹å¯åŠ¨\n")
            
            # é‡å®šå‘åˆ°è¯¥æ—¥å¿—æ–‡ä»¶ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
            class TeeOutput:
                def __init__(self, *files):
                    self.files = files
                def write(self, data):
                    for f in self.files:
                        f.write(data)
                        f.flush()
                def flush(self):
                    for f in self.files:
                        f.flush()
            
            log_file_obj = open(temp_log_file, 'a', buffering=1)  # è¡Œç¼“å†²
            sys.stdout = TeeOutput(sys.__stdout__, log_file_obj)
            sys.stderr = TeeOutput(sys.__stderr__, log_file_obj)
            
            print(f"ğŸ“ Worker {worker_id} æ—¥å¿—: {temp_log_file}")
        except Exception as e:
            print(f"âš ï¸  æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶ {temp_log_file}: {e}")
    
    worker = DistributedWorkerServer(tools_config, host, port, worker_id, master_url, log_file=log_file)
    worker.run()


def create_merged_yaml_from_bootcamp_registry(bootcamp_registry_path, output_yaml_path):
    """
    ä»bootcampæ³¨å†Œè¡¨åˆ›å»ºåˆå¹¶çš„å·¥å…·é…ç½®yamlæ–‡ä»¶
    
    Args:
        bootcamp_registry_path: bootcampæ³¨å†Œè¡¨æ–‡ä»¶è·¯å¾„(.jsonlæ ¼å¼)
        output_yaml_path: è¾“å‡ºçš„åˆå¹¶yamlæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: åˆ›å»ºçš„åˆå¹¶yamlæ–‡ä»¶è·¯å¾„
    """
    if not os.path.exists(bootcamp_registry_path):
        raise FileNotFoundError(f"Bootcampæ³¨å†Œè¡¨æ–‡ä»¶ä¸å­˜åœ¨: {bootcamp_registry_path}")
    
    merged_tools = []
    
    try:
        with jsonlines.open(bootcamp_registry_path, 'r') as reader:
            for entry in reader:
                yaml_tool_path = entry.get('yaml_tool_path')
                if not yaml_tool_path:
                    print(f"âš ï¸  è­¦å‘Š: æ³¨å†Œè¡¨æ¡ç›®ç¼ºå°‘yaml_tool_pathå­—æ®µ: {entry}")
                    continue
                
                # # å¤„ç†ç›¸å¯¹è·¯å¾„ - ç›¸å¯¹äºæ³¨å†Œè¡¨æ–‡ä»¶çš„ç›®å½•
                # if not os.path.isabs(yaml_tool_path):
                #     registry_dir = os.path.dirname(bootcamp_registry_path)
                #     yaml_tool_path = os.path.join(registry_dir, yaml_tool_path)
                
                if not os.path.exists(yaml_tool_path):
                    print(f"âš ï¸  è­¦å‘Š: å·¥å…·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {yaml_tool_path}")
                    raise FileNotFoundError(f"å·¥å…·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {yaml_tool_path}")
                
                # åŠ è½½yamlæ–‡ä»¶ä¸­çš„toolsé…ç½®
                try:
                    with open(yaml_tool_path, 'r', encoding='utf-8') as f:
                        yaml_config = yaml.safe_load(f)
                    
                    tools = yaml_config.get('tools', [])
                    if tools:
                        merged_tools.extend(tools)
                        print(f"âœ… ä» {yaml_tool_path} åŠ è½½äº† {len(tools)} ä¸ªå·¥å…·")
                    else:
                        print(f"âš ï¸  è­¦å‘Š: {yaml_tool_path} ä¸­æ²¡æœ‰æ‰¾åˆ°toolsé…ç½®")
                        
                except Exception as e:
                    print(f"âŒ åŠ è½½å·¥å…·é…ç½®æ–‡ä»¶å¤±è´¥: {yaml_tool_path}, é”™è¯¯: {e}")
                    continue
    
    except Exception as e:
        raise RuntimeError(f"è¯»å–bootcampæ³¨å†Œè¡¨å¤±è´¥: {e}")
    
    # åˆ›å»ºåˆå¹¶çš„yamlæ–‡ä»¶
    merged_yaml_content = {'tools': merged_tools}
    os.makedirs(os.path.dirname(output_yaml_path), exist_ok=True)
    with open(output_yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(merged_yaml_content, f, default_flow_style=False, allow_unicode=True)
    
    print(f"ğŸ“‹ æ€»å…±ä»bootcampæ³¨å†Œè¡¨åŠ è½½äº† {len(merged_tools)} ä¸ªå·¥å…·é…ç½®")
    print(f"ğŸ“ å·²åˆ›å»ºåˆå¹¶çš„å·¥å…·é…ç½®æ–‡ä»¶: {output_yaml_path}")
    return output_yaml_path


def start_multiple_workers(tools_config, host, start_port, master_url, num_workers, log_file=None):
    """å¯åŠ¨å¤šä¸ªWorkerè¿›ç¨‹"""
    worker_processes = []
    worker_urls = []
    current_port = start_port
    
    print(f"--- å¯åŠ¨ {num_workers} ä¸ªWorkerè¿›ç¨‹ ---")
    
    for i in range(num_workers):
        worker_port = current_port
        # Generate a random short id for the worker
        worker_id = f"{uuid.uuid4().hex[:8]}"
        worker_url = f"http://{get_external_ip()}:{worker_port}"
        worker_urls.append(worker_url)
        
        process = multiprocessing.Process(
            target=start_worker_process, 
            args=(tools_config, host, worker_port, worker_id, master_url, log_file)
        )
        process.start()
        worker_processes.append(process)
        current_port = worker_port + 1
    
    return worker_processes, worker_urls


def test_servers(server_url, tool_names, test_timeout=10, connectivity_only=False):
    """æµ‹è¯•æœåŠ¡å™¨åŠŸèƒ½"""
    print(f"ğŸ§ª æµ‹è¯•æœåŠ¡å™¨: {server_url}")
    
    try:
        # åŸºç¡€è¿é€šæ€§æµ‹è¯•
        print(f"ğŸ” æµ‹è¯•Masterè¿é€šæ€§: {server_url}/health")
        response = requests.get(f"{server_url}/health", timeout=test_timeout)
        if response.status_code == 200:
            data = response.json()
            print("  âœ… Masterå¥åº·æ£€æŸ¥é€šè¿‡")
            print(f"    - æ”¯æŒå·¥å…·: {data.get('tools', [])}")
            print(f"    - æ³¨å†ŒWorkeræ•°: {data.get('registered_workers', 0)}")
            print(f"    - æ´»è·ƒWorkeræ•°: {len([w for w in data.get('workers', {}).values() if w.get('status') == 'alive'])}")
            
            if not connectivity_only:
                # è¯¦ç»†ç«¯ç‚¹æµ‹è¯•
                print(f"\nğŸ§ª æµ‹è¯•å·¥å…·ç«¯ç‚¹...")
                
                for tool_name in tool_names:
                    print(f"\n--- æµ‹è¯•å·¥å…·: {tool_name} ---")
                    success = True
                    
                    # æµ‹è¯•åˆ›å»ºç«¯ç‚¹
                    try:
                        create_url = f"{server_url}/{tool_name}/create"
                        test_data = {"instance_id": f"test_instance_{tool_name}", "identity": {"test": True}}
                        response = requests.post(create_url, json=test_data, timeout=test_timeout)
                        if response.status_code == 200 and response.json().get("success"):
                            print(f"  âœ… åˆ›å»ºç«¯ç‚¹æµ‹è¯•é€šè¿‡: {create_url}")
                        else:
                            print(f"  âŒ åˆ›å»ºç«¯ç‚¹æµ‹è¯•å¤±è´¥: çŠ¶æ€ç  {response.status_code}")
                            success = False
                    except Exception as e:
                        print(f"  âŒ åˆ›å»ºç«¯ç‚¹è¯·æ±‚å¤±è´¥: {e}")
                        success = False

                    # æµ‹è¯•æ‰§è¡Œç«¯ç‚¹
                    try:
                        execute_url = f"{server_url}/{tool_name}/execute"
                        test_data = {"instance_id": f"test_instance_{tool_name}", "test_param": "value"}
                        response = requests.post(execute_url, json=test_data, timeout=test_timeout)
                        if response.status_code == 200:
                            print(f"  âœ… æ‰§è¡Œç«¯ç‚¹æµ‹è¯•é€šè¿‡: {execute_url}")
                        else:
                            print(f"  âŒ æ‰§è¡Œç«¯ç‚¹æµ‹è¯•å¤±è´¥: çŠ¶æ€ç  {response.status_code}")
                            success = False
                    except Exception as e:
                        print(f"  âŒ æ‰§è¡Œç«¯ç‚¹è¯·æ±‚å¤±è´¥: {e}")
                        success = False

                    # æµ‹è¯•é‡Šæ”¾ç«¯ç‚¹
                    try:
                        release_url = f"{server_url}/{tool_name}/release"
                        test_data = {"instance_id": f"test_instance_{tool_name}"}
                        response = requests.post(release_url, json=test_data, timeout=test_timeout)
                        if response.status_code == 200 and response.json().get("success"):
                            print(f"  âœ… é‡Šæ”¾ç«¯ç‚¹æµ‹è¯•é€šè¿‡: {release_url}")
                        else:
                            print(f"  âš ï¸  é‡Šæ”¾ç«¯ç‚¹æµ‹è¯•å¤±è´¥: çŠ¶æ€ç  {response.status_code}")
                    except Exception as e:
                        print(f"  âš ï¸  é‡Šæ”¾ç«¯ç‚¹è¯·æ±‚å¤±è´¥: {e}")
                    
                    status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
                    print(f"  å·¥å…· {tool_name}: {status}")
            
            print("ğŸ‰ æœåŠ¡å™¨æµ‹è¯•å®Œæˆï¼")
        else:
            print(f"  âŒ Masterå¥åº·æ£€æŸ¥å¤±è´¥: çŠ¶æ€ç  {response.status_code}")
            
    except Exception as e:
        print(f"  âŒ æœåŠ¡å™¨æµ‹è¯•å¤±è´¥: {e}")


def log_message(message: str, log_path=None):
    """è®°å½•æ—¥å¿—æ¶ˆæ¯åˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
    log_line = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}"
    if log_path:
        with open(log_path, 'a', encoding='utf-8') as f:
            f.write(log_line + '\n')
    print(log_line)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åˆ†å¸ƒå¼Master-WorkeræœåŠ¡å™¨æ¶æ„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

1. å¯åŠ¨MasteræœåŠ¡å™¨ (åŠ¨æ€å·¥å…·å‘ç°):
   python cli.py --mode master --port 8000

2. å¯åŠ¨MasteræœåŠ¡å™¨ (é¢„é…ç½®å·¥å…·):
   python cli.py --mode master --tools_yaml_path config.yaml --port 8000

3. åœ¨å…¶ä»–æœºå™¨ä¸Šå¯åŠ¨Worker:
   python cli.py --mode worker --tools_yaml_path config.yaml --master_url http://master_ip:8000 --port 8001 --num_workers 3

4. å¯åŠ¨ç»Ÿä¸€æœåŠ¡å™¨ï¼ˆå•æœºMaster+å¤šWorkeræ¨¡å¼ï¼‰:
   python cli.py --mode unified --tools_yaml_path config.yaml --port 8000 --num_workers 8
   python cli.py --mode unified --tools_yaml_path config.yaml --port 8000 --keep_running --num_workers 8
   python cli.py --mode unified --tools_yaml_path config.yaml --port 8000 --test_servers --keep_running --timeout_per_query 600 --num_workers 5
        """
    )
    
    parser.add_argument(
        "--mode", 
        choices=["master", "worker", "unified"],
        required=True,
        help="è¿è¡Œæ¨¡å¼: master(MasteræœåŠ¡å™¨), worker(WorkeræœåŠ¡å™¨), unified(ç»Ÿä¸€æœåŠ¡å™¨)"
    )
    parser.add_argument(
        "--tools_yaml_path", 
        required=False,
        help="å·¥å…·é…ç½®YAMLæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--bootcamp_registry",
        required=False,
        help="bootcampæ³¨å†Œè¡¨ï¼Œæä¾›åå¯å°†æ³¨å†Œè¡¨é‡Œæ‰€æœ‰bootcampçš„toolæŒ‚è½½åˆ°woker server"
    )
    parser.add_argument(
        "--port", 
        type=int, 
        default=8000,
        help="æœåŠ¡å™¨ç«¯å£å· (é»˜è®¤: 8000)"
    )
    parser.add_argument(
        "--host", 
        default="0.0.0.0",
        help="æœåŠ¡å™¨ä¸»æœºåœ°å€ (é»˜è®¤: 0.0.0.0)"
    )
    parser.add_argument(
        "--master_url", 
        help="MasteræœåŠ¡å™¨URL (Workeræ¨¡å¼å¿…éœ€)"
    )
    parser.add_argument(
        "--worker_id", 
        help="Worker ID (Workeræ¨¡å¼ä½¿ç”¨ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ)"
    )
    parser.add_argument(
        "--output_dir", 
        default=None,
        help="è¾“å‡ºç›®å½• (é»˜è®¤: ä¸è¾“å…¥é…ç½®æ–‡ä»¶åŒç›®å½•)"
    )
    parser.add_argument(
        "--updated_tool_class", 
        default="internbootcamp.src.base_mcp_tool.BaseMCPTool",
        help="æ›´æ–°åçš„tool classåç§° (é»˜è®¤: internbootcamp.src.base_mcp_tool.BaseMCPTool)"
    )
    parser.add_argument(
        "--timeout_per_query",
        type=int,
        default=600,
        help="æ¯ä¸ªæŸ¥è¯¢çš„è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 600)"
    )
    parser.add_argument(
        "--num_workers", 
        type=int,
        default=1,
        help="WorkeræœåŠ¡å™¨æ•°é‡ (é»˜è®¤: 3) - Workerå’Œunifiedæ¨¡å¼ä½¿ç”¨"
    )
    # unifiedæ¨¡å¼å‚æ•°
    parser.add_argument(
        "--keep_running", 
        action="store_true",
        help="ä¿æŒæœåŠ¡å™¨è¿è¡Œ (é»˜è®¤: åˆ›å»ºåç«‹å³é€€å‡º) - unifiedæ¨¡å¼ä½¿ç”¨"
    )
    parser.add_argument(
        "--log_dir", 
        default=None,
        help="æ—¥å¿—ç›®å½•è·¯å¾„ï¼Œç”¨äºä¿å­˜æœåŠ¡å™¨æ—¥å¿— (é»˜è®¤: ä¸è®°å½•æ—¥å¿—) - unifiedæ¨¡å¼ä½¿ç”¨"
    )
    parser.add_argument(
        "--test_servers", 
        action="store_true",
        help="å¯åŠ¨åæµ‹è¯•æ‰€æœ‰æœåŠ¡å™¨ (é»˜è®¤: ä¸æµ‹è¯•) - unifiedæ¨¡å¼ä½¿ç”¨"
    )
    parser.add_argument(
        "--test_timeout", 
        type=int,
        default=10,
        help="æµ‹è¯•è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 10) - unifiedæ¨¡å¼ä½¿ç”¨"
    )
    parser.add_argument(
        "--connectivity_only", 
        action="store_true",
        help="ä»…æµ‹è¯•è¿é€šæ€§ï¼Œä¸æµ‹è¯•å…·ä½“ç«¯ç‚¹ (é»˜è®¤: æµ‹è¯•æ‰€æœ‰åŠŸèƒ½) - unifiedæ¨¡å¼ä½¿ç”¨"
    )
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not args.bootcamp_registry and not args.tools_yaml_path and args.mode != "master":
        print("âŒ é”™è¯¯: Workerå’ŒUnifiedæ¨¡å¼å¿…é¡»æŒ‡å®š --tools_yaml_path æˆ– --bootcamp_registry å…¶ä¸­ä¹‹ä¸€")
        sys.exit(1)
    
    if args.bootcamp_registry and not os.path.exists(args.bootcamp_registry):
        print(f"âŒ é”™è¯¯: bootcampæ³¨å†Œè¡¨æ–‡ä»¶ä¸å­˜åœ¨: {args.bootcamp_registry}")
        sys.exit(1)
        
    if args.tools_yaml_path and not os.path.exists(args.tools_yaml_path):
        print(f"âŒ é”™è¯¯: å·¥å…·é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.tools_yaml_path}")
        sys.exit(1)
    
    # éªŒè¯Workeræ¨¡å¼å‚æ•°
    if args.mode == "worker" and not args.master_url:
        print("âŒ é”™è¯¯: Workeræ¨¡å¼å¿…é¡»æŒ‡å®š --master_url")
        sys.exit(1)
    
    temp_yaml_file = None  # ç”¨äºè·Ÿè¸ªéœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶
    try:
        # åŠ è½½å·¥å…·é…ç½®
        tools_config = []
        if args.bootcamp_registry:
            print(f"ğŸ“– ä»bootcampæ³¨å†Œè¡¨åˆå¹¶å·¥å…·é…ç½®: {args.bootcamp_registry}")
            # åˆ›å»ºä¸´æ—¶åˆå¹¶yamlæ–‡ä»¶
            temp_yaml_path = os.path.join(os.path.dirname(args.bootcamp_registry), "merged_tools_temp.yaml")
            args.tools_yaml_path = create_merged_yaml_from_bootcamp_registry(args.bootcamp_registry, temp_yaml_path)
            temp_yaml_file = temp_yaml_path
            
        if args.tools_yaml_path:
            print(f"ğŸ“– åŠ è½½å·¥å…·é…ç½®: {args.tools_yaml_path}")
            tools_config = load_tools_config(args.tools_yaml_path)
            print(f"æ‰¾åˆ° {len(tools_config)} ä¸ªå·¥å…·é…ç½®")
        elif args.mode == "master":
            print("ğŸ“– Masteræ¨¡å¼: æœªæä¾›å·¥å…·é…ç½®ï¼Œå°†ä½¿ç”¨åŠ¨æ€å·¥å…·å‘ç°")
        else:
            # è¿™ç§æƒ…å†µåº”è¯¥åœ¨å‰é¢çš„éªŒè¯ä¸­è¢«æ‹¦æˆª
            raise ValueError("Workerå’ŒUnifiedæ¨¡å¼å¿…é¡»æä¾›å·¥å…·é…ç½®")
        
        # ä¿¡å·å¤„ç†
        def signal_handler(signum, frame):
            print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨é€€å‡º...")
            sys.exit(0)
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        if args.mode == "master":
            # å¯åŠ¨MasteræœåŠ¡å™¨
            print(f"\nğŸš€ å¯åŠ¨åˆ†å¸ƒå¼MasteræœåŠ¡å™¨...")
            server = DistributedMasterServer(args.host, args.port, tools_config if tools_config else None)
            
            master_url = f"http://{get_external_ip()}:{args.port}"
            
            # åˆ›å»ºè¾“å‡ºé…ç½®æ–‡ä»¶ï¼ˆä»…å½“æœ‰å·¥å…·é…ç½®æ—¶ï¼‰
            if args.tools_yaml_path:
                if args.output_dir is None:
                    args.output_dir = os.path.dirname(args.tools_yaml_path)
                os.makedirs(args.output_dir, exist_ok=True)
                
                original_name = Path(args.tools_yaml_path).stem
                updated_yaml_path = os.path.join(args.output_dir, f"{original_name}_with_server_urls.yaml")
                
                print(f"ğŸ“ åˆ›å»ºé…ç½®æ–‡ä»¶: {updated_yaml_path}")
                update_tools_config_with_urls(args.tools_yaml_path, master_url, updated_yaml_path, 
                                            args.updated_tool_class, args.timeout_per_query)
                
                print(f"ğŸ“„ Masteré…ç½®æ–‡ä»¶: {updated_yaml_path}")
            else:
                print("ğŸ“„ æœªæä¾›å·¥å…·é…ç½®ï¼ŒMasterå°†é€šè¿‡Workeræ³¨å†ŒåŠ¨æ€å‘ç°å·¥å…·")
            
            print(f"ğŸŒ Master URL: {master_url}")
            print(f"ğŸ“‹ Workeræ³¨å†Œåœ°å€: {master_url}/register_worker")
            
            server.run()
            
        elif args.mode == "worker":
            # æ£€æŸ¥æ˜¯å¦åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼ˆrjobç­‰ï¼‰
            node_rank = int(os.getenv("NODE_RANK", "0"))
            node_count = int(os.getenv("NODE_COUNT", "1"))
            hostname = socket.gethostname()
            
            # éšæœºåç½®è°ƒæ•´ç«¯å£ï¼Œé¿å…ç«¯å£å†²çª
            adjusted_port = args.port + random.randint(0, 100) + node_rank % 256
            
            # è¾“å‡ºèŠ‚ç‚¹ä¿¡æ¯
            print("\n" + "=" * 50)
            print("ğŸ–¥ï¸  Worker èŠ‚ç‚¹ä¿¡æ¯")
            print("=" * 50)
            print(f"  NODE_RANK:    {node_rank}")
            print(f"  NODE_COUNT:   {node_count}")
            print(f"  HOSTNAME:     {hostname}")
            print(f"  Start Port:     {args.port}")
            print(f"  Adjusted Port:   {adjusted_port}")
            print(f"  Master URL:   {args.master_url}")
            print(f"  Worker Nums:   {args.num_workers}")
            print("=" * 50 + "\n")
            
            # æ£€æŸ¥ Master æœåŠ¡æ˜¯å¦å¯ç”¨
            if args.master_url:
                print(f"ğŸ” æ£€æŸ¥ Master æœåŠ¡: {args.master_url}")
                for attempt in range(1, 11):
                    try:
                        response = requests.get(
                            f"{args.master_url}/health",
                            timeout=3
                        )
                        if response.status_code == 200:
                            print(f"âœ… Master æœåŠ¡å¯ç”¨")
                            break
                    except Exception as e:
                        if attempt < 10:
                            print(f"â³ ç­‰å¾… Master æœåŠ¡... (å°è¯• {attempt}/10)")
                            time.sleep(2)
                        else:
                            print(f"âš ï¸  è­¦å‘Š: Master æœåŠ¡å¯èƒ½ä¸å¯ç”¨: {e}")
                            print(f"âš ï¸  å°†ç»§ç»­å¯åŠ¨ Workerï¼Œä½†æ³¨å†Œå¯èƒ½å¤±è´¥")
                
                print()  # ç©ºè¡Œ
            
            # å¯åŠ¨WorkeræœåŠ¡å™¨ï¼ˆæ”¯æŒå¤šä¸ªWorkerï¼‰
            print(f"ğŸš€ å¯åŠ¨ {args.num_workers} ä¸ªåˆ†å¸ƒå¼WorkeræœåŠ¡å™¨...")
            
            # ä½¿ç”¨è°ƒæ•´åçš„ç«¯å£
            worker_processes, worker_urls = start_multiple_workers(
                tools_config, args.host, adjusted_port, args.master_url, args.num_workers
            )
            
            print(f"ğŸ†” å¯åŠ¨äº† {len(worker_processes)} ä¸ªWorkerè¿›ç¨‹")
            print(f"ğŸ“‹ Worker URLs: {worker_urls}")
            print(f"ğŸ’¾ æ—¥å¿—æç¤º: å­è¿›ç¨‹æ—¥å¿—å¯èƒ½åœ¨ /tmp/worker_*.log\n")
            
            try:
                # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹
                for process in worker_processes:
                    process.join()
            except KeyboardInterrupt:
                print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰Worker...")
                for process in worker_processes:
                    if process.is_alive():
                        process.terminate()
                        process.join(timeout=5)
            
        elif args.mode == "unified":
            # å¯åŠ¨ç»Ÿä¸€æœåŠ¡å™¨ï¼ˆMaster + å¤šä¸ªWorkerï¼‰
            print(f"\nğŸš€ å¯åŠ¨ç»Ÿä¸€æœåŠ¡å™¨ï¼ˆMaster + {args.num_workers} ä¸ªWorkerï¼‰...")
            
            external_ip = get_external_ip()
            
            # åˆ›å»ºé…ç½®æ–‡ä»¶
            if args.output_dir is None:
                args.output_dir = os.path.dirname(args.tools_yaml_path)
            os.makedirs(args.output_dir, exist_ok=True)
            
            original_name = Path(args.tools_yaml_path).stem
            updated_yaml_path = os.path.join(args.output_dir, f"{original_name}_with_server_urls.yaml")
            server_url = f"http://{external_ip}:{args.port}"
            
            print(f"ğŸ“ åˆ›å»ºé…ç½®æ–‡ä»¶: {updated_yaml_path}")
            update_tools_config_with_urls(args.tools_yaml_path, server_url, updated_yaml_path, 
                                        args.updated_tool_class, args.timeout_per_query)
            
            print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {updated_yaml_path}")
            print(f"ğŸŒ MasteræœåŠ¡å™¨URL: {server_url}")
            
            # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
            unified_log_path = None
            if args.log_dir:
                os.makedirs(args.log_dir, exist_ok=True)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                unified_log_path = os.path.join(args.log_dir, f"unified_server_{timestamp}.log")
                print(f"ğŸ“„ ç»Ÿä¸€æ—¥å¿—æ–‡ä»¶: {unified_log_path}")
                
                # å†™å…¥å¯åŠ¨ä¿¡æ¯
                with open(unified_log_path, 'w', encoding='utf-8') as f:
                    f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ğŸš€ å¼€å§‹å¯åŠ¨ç»Ÿä¸€æœåŠ¡å™¨\n")
                    f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Workeræ•°é‡: {args.num_workers}\n")
                    f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Masterç«¯å£: {args.port}\n")
                    f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] IP: {external_ip}\n")
                    f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] é…ç½®æ–‡ä»¶: {updated_yaml_path}\n")
            
            # å­˜å‚¨è¿›ç¨‹å¼•ç”¨ä»¥ä¾¿æ¸…ç†
            worker_processes = []
            master_process = None
            
            try:
                # 1. å¯åŠ¨Masterè¿›ç¨‹
                log_message("--- å¯åŠ¨MasteræœåŠ¡å™¨ ---", unified_log_path)
                
                master_process = multiprocessing.Process(
                    target=start_master_process,
                    args=(tools_config, args.host, args.port, unified_log_path)
                )
                master_process.start()
                
                # ç­‰å¾…Masterå¯åŠ¨
                log_message("â³ ç­‰å¾…Masterå¯åŠ¨å®Œæˆ...", unified_log_path)
                time.sleep(3)
                
                if not master_process.is_alive():
                    raise RuntimeError("MasteræœåŠ¡å™¨å¯åŠ¨å¤±è´¥")
                
                log_message(f"âœ… MasteræœåŠ¡å™¨å¯åŠ¨æˆåŠŸäºç«¯å£ {args.port}", unified_log_path)
                
                # 2. å¯åŠ¨Workerè¿›ç¨‹
                worker_processes, worker_urls = start_multiple_workers(
                    tools_config, args.host, args.port + 1, server_url, args.num_workers, unified_log_path
                )
                
                # ç­‰å¾…Workerå¯åŠ¨å¹¶æ³¨å†Œ
                log_message("â³ ç­‰å¾…æ‰€æœ‰Workerå¯åŠ¨å¹¶æ³¨å†Œåˆ°Master...", unified_log_path)
                time.sleep(5)
                
                # éªŒè¯Workeræ˜¯å¦å¯åŠ¨æˆåŠŸ
                alive_workers = []
                for i, process in enumerate(worker_processes):
                    if process.is_alive():
                        alive_workers.append(worker_urls[i])
                        log_message(f"  âœ… Worker {i+1} å¯åŠ¨è¿›ç¨‹è¿è¡Œæ­£å¸¸", unified_log_path)
                    else:
                        log_message(f"  âŒ Worker {i+1} å¯åŠ¨è¿›ç¨‹è¿è¡Œå¤±è´¥", unified_log_path)
                
                if not alive_workers:
                    raise RuntimeError("æ²¡æœ‰WorkeræˆåŠŸå¯åŠ¨")
                
                # æµ‹è¯•æœåŠ¡å™¨åŠŸèƒ½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if args.test_servers:
                    from .utils import extract_tool_names_from_config
                    tool_names = extract_tool_names_from_config(tools_config)
                    
                    log_message("ğŸ§ª æµ‹è¯•ç»Ÿä¸€æœåŠ¡å™¨...", unified_log_path)
                    time.sleep(3)  # ç­‰å¾…å®Œå…¨å¯åŠ¨
                    
                    test_servers(server_url, tool_names, args.test_timeout, args.connectivity_only)
                    
                    if not args.keep_running:
                        print(f"\nâš ï¸  æµ‹è¯•å®Œæˆï¼ŒæœåŠ¡å™¨å°†åœæ­¢")
                        return
                
                log_message("ğŸ‰ ç»Ÿä¸€æœåŠ¡å™¨æ¶æ„å¯åŠ¨å®Œæˆï¼", unified_log_path)
                log_message(f"   - Master: {server_url}", unified_log_path)
                log_message(f"   - Workers: {len(alive_workers)} ä¸ª", unified_log_path)
                if args.log_dir:
                    log_message(f"ğŸ“Š æ—¥å¿—ä¿å­˜åˆ°: {unified_log_path}", unified_log_path)
                
                if args.keep_running:
                    log_message("ğŸ”„ æœåŠ¡å™¨å°†æŒç»­è¿è¡Œ... (æŒ‰ Ctrl+C åœæ­¢)", unified_log_path)
                    
                    try:
                        # ç›‘æ§æ‰€æœ‰è¿›ç¨‹
                        while True:
                            time.sleep(10)
                            
                            # æ£€æŸ¥Masterè¿›ç¨‹
                            if not master_process.is_alive():
                                print(f"âš ï¸  Masterè¿›ç¨‹å·²åœæ­¢")
                                break
                            
                            # æ£€æŸ¥Workerè¿›ç¨‹
                            dead_workers = []
                            for i, process in enumerate(worker_processes):
                                if not process.is_alive():
                                    dead_workers.append(i+1)
                            
                            if dead_workers:
                                print(f"âš ï¸  Workerè¿›ç¨‹å·²åœæ­¢: {dead_workers}")
                                break
                                
                    except KeyboardInterrupt:
                        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
                else:
                    print(f"\nâš ï¸  æ³¨æ„: ä½¿ç”¨ --keep_running å‚æ•°æ¥ä¿æŒæœåŠ¡å™¨è¿è¡Œ")
                    print(f"âš ï¸  æœåŠ¡å™¨è¿›ç¨‹å°†åœ¨è„šæœ¬é€€å‡ºåç»§ç»­è¿è¡Œ")
                
            finally:
                # æ¸…ç†è¿›ç¨‹
                if not args.keep_running:
                    log_message("æ¸…ç†è¿›ç¨‹...", unified_log_path)
                    
                    if master_process and master_process.is_alive():
                        master_process.terminate()
                        master_process.join(timeout=5)
                        log_message("âœ… Masterè¿›ç¨‹å·²åœæ­¢", unified_log_path)
                    
                    for i, process in enumerate(worker_processes):
                        if process.is_alive():
                            process.terminate()
                            process.join(timeout=5)
                            log_message(f"âœ… Worker {i+1} è¿›ç¨‹å·²åœæ­¢", unified_log_path)
                    
                    # è®°å½•æœ€ç»ˆæ¸…ç†å®Œæˆ
                    if unified_log_path:
                        with open(unified_log_path, 'a', encoding='utf-8') as f:
                            f.write(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ğŸ ç»Ÿä¸€æœåŠ¡å™¨å·²åœæ­¢\n")
            
    except Exception as e:
        print(f"âŒ è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_yaml_file and os.path.exists(temp_yaml_file):
            try:
                os.remove(temp_yaml_file)
                print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_yaml_file}")
            except Exception as e:
                print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


if __name__ == "__main__":
    if __name__ == '__main__':
        multiprocessing.set_start_method('spawn') 
    main() 